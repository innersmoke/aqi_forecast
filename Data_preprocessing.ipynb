{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DLa9bEaXDlmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = '/content/process_pearse_street_data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Convert 'Date and Time' to datetime and set it as the index\n",
        "data['Date and Time'] = pd.to_datetime(data['Date and Time'])\n",
        "data.set_index('Date and Time', inplace=True)"
      ],
      "metadata": {
        "id": "3vunWECMDuVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "MgrhqZEoqZbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['Hour', 'DayOfWeek', 'Month'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ghq6wbUIqd2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "O3zCFamGqpXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing PM10 values\n",
        "data_cleaned = data.dropna(subset=['PM10'])\n",
        "\n",
        "# Resample to daily average\n",
        "df = data_cleaned.resample('D').mean()\n",
        "\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "wnF1uZ_5Dzc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time series plot for each pollutant\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.plot(df.index, df['PM10'], label='PM10')\n",
        "plt.plot(df.index, df['NO2'], label='NO2')\n",
        "#plt.plot(df.index, df['O3'], label='O3')\n",
        "plt.plot(df.index, df['PM2.5'], label='PM2.5')\n",
        "plt.title('Time Series of Pollutants')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Concentration')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oKzX7zhwDK-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram for each pollutant\n",
        "df[['PM10', 'NO2', 'PM2.5']].hist(bins=30, figsize=(14, 10))\n",
        "plt.suptitle('Histograms of Pollutants')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kIpLf1OTDX8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plot for each pollutant\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(data=df[['PM10', 'NO2', 'PM2.5']])\n",
        "plt.title('Box Plots of Pollutants')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8e_naOVhDYnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair plot\n",
        "sns.pairplot(df[['PM10', 'NO2', 'PM2.5']])\n",
        "plt.suptitle('Pair Plots of Pollutants')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v7SnENhEDc4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0, linewidths=0.5, linecolor='black')\n",
        "plt.title('Correlation Heatmap for All Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "niQclwJsDbFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lag plot for PM10\n",
        "pd.plotting.lag_plot(df['PM10'])\n",
        "plt.title('Lag Plot of PM10')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W9HN_7KXDjAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rolling mean and standard deviation plot for PM10\n",
        "plt.figure(figsize=(14, 8))\n",
        "rolling_mean = df['PM10'].rolling(window=12).mean()\n",
        "rolling_std = df['PM10'].rolling(window=12).std()\n",
        "plt.plot(df['PM10'], label='PM10')\n",
        "plt.plot(rolling_mean, label='Rolling Mean')\n",
        "plt.plot(rolling_std, label='Rolling Std')\n",
        "plt.title('Rolling Mean and Standard Deviation of PM10')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "saVLhb7_DjiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ACF and PACF for the PM10\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# ACF plot\n",
        "plot_acf(df['PM10'].dropna(), lags=40, ax=axes[0])\n",
        "axes[0].set_title('Autocorrelation Function (ACF)')\n",
        "\n",
        "# PACF plot\n",
        "plot_pacf(df['PM10'].dropna(), lags=40, ax=axes[1])\n",
        "axes[1].set_title('Partial Autocorrelation Function (PACF)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EzRH3mLtD4Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lag features for PM10 based on significant lags based on ACF and PACF plots\n",
        "for lag in range(1, 4):\n",
        "    df[f'PM10_Lag_{lag}'] = df['PM10'].shift(lag)\n",
        "\n",
        "# Create rolling mean features for PM10\n",
        "df['PM10_RollingMean_3'] = df['PM10'].rolling(window=3).mean()\n",
        "df['PM10_RollingMean_7'] = df['PM10'].rolling(window=7).mean()\n",
        "df['PM10_RollingMean_1'] = df['PM10'].rolling(window=1).mean()\n",
        "df['PM10_RollingMean_10'] = df['PM10'].rolling(window=10).mean()\n",
        "\n",
        "# Create lag features for other pollutants (NO2, O3, PM2.5)\n",
        "for pollutant in ['NO2', 'PM2.5']:\n",
        "    for lag in range(1, 8):\n",
        "        df[f'{pollutant}_Lag_{lag}'] = df[pollutant].shift(lag)\n",
        "\n",
        "# Create rolling mean features for other pollutants\n",
        "for pollutant in ['NO2', 'PM2.5']:\n",
        "    df[f'{pollutant}_RollingMean_3'] = df[pollutant].rolling(window=3).mean()\n",
        "    df[f'{pollutant}_RollingMean_7'] = df[pollutant].rolling(window=7).mean()\n",
        "\n",
        "# Drop rows with NaN values resulting from the lag and rolling mean operations\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "UVh9rvg-D-JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percent change for each pollutant\n",
        "df['NO2_Pct_Change'] = df['NO2'].pct_change() * 100\n",
        "#df['O3_Pct_Change'] = df['O3'].pct_change() * 100\n",
        "df['PM10_Pct_Change'] = df['PM10'].pct_change() * 100\n",
        "df['PM2.5_Pct_Change'] = df['PM2.5'].pct_change() * 100\n",
        "\n",
        "# Drop rows with NaN values resulting from the percent change calculation\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "zHQEnszLEB4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create derived features\n",
        "df['Day_of_Week'] = df.index.dayofweek\n",
        "df['Is_Weekend'] = df['Day_of_Week'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "#df['NO2_O3_Ratio'] = df['NO2'] / df['O3']\n",
        "df['PM10_NO2_Product'] = df['PM10'] * df['NO2']\n",
        "df['PM10_PM2.5_Ratio'] = df['PM10'] / df['PM2.5']\n",
        "df['NO2_RollingStd_3'] = df['NO2'].rolling(window=3).std()\n",
        "#df['O3_RollingMax_7'] = df['O3'].rolling(window=7).max()\n",
        "df['PM2.5_RollingMin_3'] = df['PM2.5'].rolling(window=3).min()\n",
        "df['Cumulative_NO2'] = df['NO2'].cumsum()\n",
        "df['Cumulative_PM10'] = df['PM10'].cumsum()\n",
        "\n",
        "# Drop rows with NaN values resulting from the rolling calculations\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "BvB6heGVEFc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnIZTZZxcX9q"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix_final = df.corr()\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(correlation_matrix_final)\n",
        "\n",
        "# Plot the correlation heatmap\n",
        "plt.figure(figsize=(14, 12))\n",
        "sns.heatmap(correlation_matrix_final, annot=True, cmap='coolwarm', center=0, linewidths=0.5, linecolor='black')\n",
        "plt.title('Correlation Heatmap for Final Dataset with Derived Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "fcWXGAQhHeXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the correlation values for PM10 and sort them in descending order\n",
        "pm10_correlations = correlation_matrix_final[['PM10']].sort_values(by='PM10', ascending=False)\n",
        "\n",
        "print(pm10_correlations)"
      ],
      "metadata": {
        "id": "LwWxBq8_Hf0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter columns with correlation higher than 0.5 with PM10\n",
        "high_corr_columns = correlation_matrix_final.index[correlation_matrix_final['PM10'].abs() > 0.5]\n",
        "filtered_df = df[high_corr_columns]"
      ],
      "metadata": {
        "id": "Xtwn_Ij4bBpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.columns"
      ],
      "metadata": {
        "id": "I3p3iFrh8OUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_vars = high_corr_columns.drop('PM10').tolist()\n",
        "print(\"Selected Variables after Linear Correlation Screening:\\n\", selected_vars)"
      ],
      "metadata": {
        "id": "VNynQiH_azij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "jBTb82vuyIc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-linear Correlation Analysis on Selected Variables\n",
        "X = df[selected_vars]\n",
        "y = df['PM10']\n",
        "\n",
        "# Mutual Information\n",
        "mi = mutual_info_regression(X, y)\n",
        "mi_df = pd.DataFrame(mi, index=X.columns, columns=['Mutual Information'])\n",
        "mi_df.sort_values(by='Mutual Information', ascending=False, inplace=True)\n",
        "\n",
        "# Random Forest Feature Importance\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(X, y)\n",
        "importance = rf.feature_importances_\n",
        "\n",
        "importance_df = pd.DataFrame(importance, index=X.columns, columns=['Importance'])\n",
        "importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
        "\n",
        "# Display results\n",
        "results_df = pd.concat([mi_df, importance_df], axis=1)\n",
        "print(\"Mutual Information and Feature Importance:\\n\", results_df)"
      ],
      "metadata": {
        "id": "F9aqb1Rezvjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "sns.pairplot(df[['PM10'] + selected_vars])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BvGjrRcg0FgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the thresholds for high importance and low mutual information\n",
        "mi_threshold = 0.1\n",
        "importance_threshold = 0.05\n",
        "\n",
        "# Identify variables to keep\n",
        "variables_to_keep = results_df[(results_df['Mutual Information'] >= mi_threshold) |\n",
        "                               (results_df['Importance'] >= importance_threshold)].index.tolist()\n",
        "\n",
        "# Sort the variables to keep by their importance and mutual information scores\n",
        "sorted_results_df = results_df.loc[variables_to_keep].sort_values(by=['Importance', 'Mutual Information'], ascending=False)\n",
        "\n",
        "# Display the most important variables\n",
        "print(\"Sorted Important Variables:\\n\", sorted_results_df)"
      ],
      "metadata": {
        "id": "ZfX429l53NR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the filtered dataframe to a CSV file\n",
        "filtered_csv_path = 'model_amiens_street_data.csv'\n",
        "filtered_df.to_csv(filtered_csv_path)\n",
        "\n",
        "# If running in Google Colab, use the following code to download the CSV file:\n",
        "from google.colab import files\n",
        "files.download(filtered_csv_path)"
      ],
      "metadata": {
        "id": "qyB4pkpnbLav"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}